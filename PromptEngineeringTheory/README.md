# ğŸ“˜ Prompt Engineering Notes

## 1. What is an LLM?
- An **LLM (Large Language Model)** is trained on massive amounts of data.  
- It works by predicting the next word in a sequence, based on probability.  
- Example: When typing in Google search or messaging apps, you get word suggestions â€” this is similar to how LLMs function.  
- When you provide input, the model tries to generate the most probable sequence of words as output.  

---

## 2. Chain of Thought (CoT)
- **Definition**: A reasoning method for LLMs.  
- Helps the model break down a complex problem into smaller steps.  
- Improves accuracy by allowing the model to â€œthink step by step.â€  

---

## 3. ReAct Prompting
- **ReAct = Reasoning + Acting**  
- The model not only reasons but also takes actions step by step.  
- Useful for tasks where breaking down the problem and taking intermediate actions lead to better results.  

---

## 4. Writing a Good Prompt
A good prompt should have:  
1. **Context** â†’ Provide necessary background.  
2. **Clarity** â†’ Clear and unambiguous instructions.  
3. **Iterative Refinement** â†’ Improve the prompt based on results.  
4. **Input Data** â†’ Can be text, image, or other formats.  
5. **Output Signal** â†’ Indicate the type of response needed (summary, explanation, list, etc.).  

---

## 5. Zero-Shot Prompting
- **Definition**: Asking the model to perform a task **without providing examples**.  
- Scope is limited since the model must rely only on the given question.  
- Example:  
  - Prompt: *â€œList 5 cities to visit in Europe.â€*  
  - No examples or context are given beforehand.  

---

## 6. Few-Shot Prompting
- **Definition**: Providing a **few examples** before asking the model to perform the task.  
- Helps the model understand exactly what kind of output you expect.  
- Example:  
  - Prompt:  
    ```
    Translate English to Spanish:  
    1. Sea otter â†’ nutria de mar  
    2. Cheese â†’ queso  
    ```  
  - Now the model follows the given examples when translating.  

---

## 7. Components of a Prompt
A prompt is made of:  
1. **Instruction** â†’ Tells the model what task to perform.  
2. **Context** â†’ Provides additional information.  
3. **Input Data** â†’ The actual content (text, image, etc.).  
4. **Output Indicator** â†’ The format or type of result you want.  

---

### ğŸ“‚ Suggested Repo Structure
```
prompt-engineering/
â”‚â”€â”€ README.md   # Main notes (theory + examples)
â”‚â”€â”€ images/     # Store handwritten reference images
â”‚â”€â”€ examples/   # Code or JSON prompt examples
```
